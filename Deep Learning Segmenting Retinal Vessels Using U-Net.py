# -*- coding: utf-8 -*-
Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WqtiGF6YwRL267MVnnqMeN8arCyLXdj1

#U-Net for retinal vessel segmentation - Deep Learning Final Project

**Project Title: Retinal Vessel Segmentation Using U-Net: A Medical Imaging
Approach**

**Name**: MD AKASH HOSSAIN

## [Part-I] Install required indipendencies

### 1. install the requirements package
"""

!pip install tqdm
!pip install matplotlib
!pip install opencv-python
!pip install tf-nightly
!pip install scikit-learn
!pip install onnxruntime
!pip install -U tf2onnx

"""## [Part-II] Data Preparation

mount the driver the following code
"""

from google.colab import drive
drive.mount('/content/drive/')

import tensorflow as tf

print(tf.__version__)
print(tf.config.list_physical_devices('GPU'))
gpus=tf.config.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab Notebooks/Datasets/DRIVE
!ls
!unzip vessel-dataset.zip
!ls

"""### Process and Generate the Training Image Patch

#### setting of dataset path

- set the parameter and dataset dir
"""

# Commented out IPython magic to ensure Python compatibility.
from glob import glob
from tqdm import tqdm
import matplotlib.pyplot as plt
from IPython import display
import numpy as np
import cv2
import os
import random
import time
import shutil
from sklearn.utils import shuffle
# %matplotlib inline

patch_size = 48        # Patch image size
patch_num = 1000       # Number of patches per training image
patch_threshold = 25   # Threshold for the patch
TRAIN_OR_VAL = 0.7
dataset_path = '/content/drive/MyDrive/Colab Notebooks/Datasets/DRIVE/'

train_dir = dataset_path + "training/"
test_dir = dataset_path + "test/"

train_image_dir = train_dir + "images/"
train_mask_dir = train_dir + "mask/"
train_groundtruth_dir = train_dir + "1st_manual/"
train_patch_dir = train_dir + "patch/"

test_image_dir = test_dir + "images/"
test_mask_dir = test_dir + "mask/"

# Get image file paths
train_image_path_list = glob(train_image_dir + "*.tif")
test_image_path_list = glob(test_image_dir + "*.tif")

# Split into training and validation sets
val_image_path_list = random.sample(train_image_path_list, int(len(train_image_path_list) * (1 - TRAIN_OR_VAL)))
train_image_path_list = [i for i in train_image_path_list if i not in val_image_path_list]

# Print counts
print("Number of training images:", len(train_image_path_list))
print("Number of validation images:", len(val_image_path_list))
print("Number of testing images:", len(test_image_path_list))

"""#### Image Preprocess"""

def restrict_normalized(imgs,mask):
    imgs_normalized = np.empty(imgs.shape)
    imgs_std = np.std(imgs)
    imgs_mean = np.mean(imgs)
    imgs_normalized = (imgs-imgs_mean)/imgs_std
    for i in range(imgs.shape[2]):
        imgs_normalized[:,:,i] = ((imgs_normalized[:,:,i] - np.min(imgs_normalized[:,:,i])) / (np.max(imgs_normalized[:,:,i])-np.min(imgs_normalized[:,:,i])))*255
    return imgs_normalized

# CLAHE (Contrast Limited Adaptive Histogram Equalization)
#adaptive histogram equalization is used. In this, image is divided into small blocks called "tiles" (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual. So in a small area, histogram would confine to a small region (unless there is noise). If noise is there, it will be amplified. To avoid this, contrast limiting is applied. If any histogram bin is above the specified contrast limit (by default 40 in OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is applied
def clahe_equalized(imgs):
  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
  imgs_equalized = np.empty(imgs.shape)
  for i in range(imgs.shape[2]):
    imgs_equalized[:,:,i] = clahe.apply(np.array(imgs[:,:,i], dtype = np.uint8))
  return imgs_equalized

def normalized(imgs):
  imgs_normalized =np.empty(imgs.shape)
  for i in range(imgs.shape[2]):
    imgs_normalized[:,:,i] =cv2.equalizeHist(imgs[:,:,i])
  return imgs_normalized

def adjust_gamma(imgs, gamma=1.0):
  invGamma = 1.0 / gamma
  table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
  # apply gamma correction using the lookup table
  new_imgs = np.empty(imgs.shape)
  for i in range(imgs.shape[2]):
    new_imgs[:,:,i] = cv2.LUT(np.array(imgs[:,:,i], dtype = np.uint8), table)
  return new_imgs

def preprocess(image,mask):

  assert np.max(mask)==1
  image=np.array(image)
  image[:,:,0]=image[:,:,0]*mask
  image[:,:,1]=image[:,:,1]*mask
  image[:,:,2]=image[:,:,2]*mask

  image=restrict_normalized(image,mask)
  image=clahe_equalized(image)
  image=adjust_gamma(image,1.2)
  image=image/255.0
  return image

"""#### Generate Image/Mask Patches"""

def check_coord(x,y,h,w,patch_size):
  if x-patch_size/2>0 and x+patch_size/2<h and y-patch_size/2>0 and y+patch_size/2<w:
    return True
  return False

def image2patch(image_path,patch_num,patch_size,training=True,show=True):
  image_name=image_path.split("/")[-1].split("_")[0]

  image=plt.imread(image_path)

  groundtruth=plt.imread(train_groundtruth_dir+image_name+"_manual1.gif")
  groundtruth=np.where(groundtruth>0,1,0)

  mask=plt.imread(train_mask_dir+image_name+"_training_mask.gif")
  mask=np.where(mask>0,1,0)

  image=preprocess(image,mask)
  #image_binary=0.8*image[:,:,1]+0.2*image[:,:,2]

  image_show=image.copy()
  groundtruth_show=np.zeros_like(image)
  groundtruth_show[:,:,0]=groundtruth.copy()
  groundtruth_show[:,:,1]=groundtruth.copy()
  groundtruth_show[:,:,2]=groundtruth.copy()

  sample_count=0
  sample_index=0

  sample_point=np.where(groundtruth==1)     # generate sample point

  state = np.random.get_state()      # shuffle the coord
  np.random.shuffle(sample_point[0])
  np.random.set_state(state)
  np.random.shuffle(sample_point[1])

  patch_image_list=[]
  patch_groundtruth_list=[]

  while sample_count<patch_num and sample_index<len(sample_point[0]):
    x,y=sample_point[0][sample_index],sample_point[1][sample_index]
    if check_coord(x,y,image.shape[0],image.shape[1],patch_size):
      if np.sum(mask[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2])>patch_threshold:     #select according to the threshold

        patch_image_binary=image[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2,:]   # patch image
        patch_groundtruth=groundtruth[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2]       # patch mask
        #patch_image_binary=np.asarray(0.25*patch_image[:,:,2]+0.75*patch_image[:,:,1])         # B*0.25+G*0.75, which enhance the vessel
        patch_groundtruth=np.where(patch_groundtruth>0,255,0)

        #patch_image_binary =cv2.equalizeHist((patch_image_binary*255.0).astype(np.uint8))/255.0

        patch_image_list.append(patch_image_binary)    # patch image
        patch_groundtruth_list.append(patch_groundtruth)             # patch mask
        if show:
          cv2.rectangle(image_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)  #draw the illustration
          cv2.rectangle(groundtruth_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)
        sample_count+=1

    if show:                                 # visualize the sample process
      plt.figure(figsize=(15,15))
      plt.title("processing: %s"%image_name)
      plt.subplot(121)
      plt.imshow(image_show,cmap=plt.cm.gray)   # processd image
      plt.subplot(122)
      plt.imshow(groundtruth_show,cmap=plt.cm.gray)  #groundtruth of the image, patch is showed as the green square
      plt.show()
      display.clear_output(wait=True)
    sample_index+=1

  for i in range(len(patch_image_list)):
    if training==True:
        plt.imsave(train_patch_dir+image_name+"-"+str(i)+"-img.jpg",patch_image_list[i])
        #print(patch_mask_list[i])
        plt.imsave(train_patch_dir+image_name+"-"+str(i)+"-groundtruth.jpg",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)
    else:
        plt.imsave(train_patch_dir+image_name+"_"+str(i)+"_val_img.jpg",patch_image_list[i])
        #print(patch_mask_list[i])
        plt.imsave(train_patch_dir+image_name+"_"+str(i)+"_val_groundtruth.jpg",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)

# delete original patch images
if not os.path.exists(train_patch_dir):
  os.mkdir(train_patch_dir)
else:
  shutil.rmtree(train_patch_dir)
  os.mkdir(train_patch_dir)

# Directory paths
dataset_path = '/content/drive/MyDrive/Colab Notebooks/Datasets/DRIVE/'
train_dir = os.path.join(dataset_path, "training/")
test_dir = os.path.join(dataset_path, "test/")
train_patch_dir = os.path.join(train_dir, "patch/")
test_save_dir = os.path.join(test_dir, "pred_result/")

# Ensure patch directories exist
if not os.path.exists(train_patch_dir):
    os.mkdir(train_patch_dir)
else:
    shutil.rmtree(train_patch_dir)
    os.mkdir(train_patch_dir)

if not os.path.exists(test_save_dir):
  os.mkdir(test_save_dir)

# generate patch images
for i in tqdm(range(len(train_image_path_list)),desc="Generate the training patches: "):
  image2patch(train_image_path_list[i],patch_num,patch_size,training=True,show=False)  # set show=True to visualize the sample process, which is much slower than show=False

for i in tqdm(range(len(val_image_path_list)),desc="Generate the val patches: "):
  image2patch(val_image_path_list[i],patch_num,patch_size,training=False,show=False)  # set show=True to visualize the sample process, which is much slower than show=False

"""## [Part-III] Model Defination"""

import tensorflow as tf
from tensorflow.keras.layers import (
    Layer,
    Conv2D,
    UpSampling2D,
    MaxPool2D,
    BatchNormalization,
    Activation,
    Concatenate,
    AveragePooling2D,
    LeakyReLU,
)

# Define LinearTransform
class LinearTransform(Layer):
    def __init__(self, patch_size, **kwargs):
        super(LinearTransform, self).__init__(**kwargs)
        self.patch_size = patch_size

        self.conv_r = Conv2D(1, kernel_size=3, strides=1, padding="same", use_bias=False)
        self.conv_g = Conv2D(1, kernel_size=3, strides=1, padding="same", use_bias=False)
        self.conv_b = Conv2D(1, kernel_size=3, strides=1, padding="same", use_bias=False)

        self.pool_rc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)
        self.pool_gc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)
        self.pool_bc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)

        self.bn = BatchNormalization()
        self.sigmoid = Activation("sigmoid")
        self.softmax = Activation("softmax")

    def call(self, input, training=True):
        r, g, b = input[:, :, :, 0:1], input[:, :, :, 1:2], input[:, :, :, 2:3]

        rs = self.conv_r(r)
        gs = self.conv_g(g)
        bs = self.conv_b(b)

        rc = tf.reshape(self.pool_rc(rs), [-1, 1])
        gc = tf.reshape(self.pool_gc(gs), [-1, 1])
        bc = tf.reshape(self.pool_bc(bs), [-1, 1])

        merge = Concatenate(axis=-1)([rc, gc, bc])
        merge = tf.expand_dims(merge, axis=1)
        merge = tf.expand_dims(merge, axis=1)
        merge = self.softmax(merge)
        merge = tf.repeat(merge, repeats=input.shape[1], axis=2)
        merge = tf.repeat(merge, repeats=input.shape[2], axis=1)

        r = r * (1 + self.sigmoid(rs))
        g = g * (1 + self.sigmoid(gs))
        b = b * (1 + self.sigmoid(bs))

        output = self.bn(
            merge[:, :, :, 0:1] * r
            + merge[:, :, :, 1:2] * g
            + merge[:, :, :, 2:3] * b,
            training=training,
        )
        return output


# Define ResBlock
class ResBlock(Layer):
    def __init__(self, out_ch, residual_path=False, stride=1):
        super(ResBlock, self).__init__()
        self.residual_path = residual_path

        self.conv1 = Conv2D(
            out_ch,
            kernel_size=3,
            strides=stride,
            padding="same",
            use_bias=False,
            data_format="channels_last",
        )
        self.bn1 = BatchNormalization()
        self.relu1 = LeakyReLU()

        self.conv2 = Conv2D(
            out_ch,
            kernel_size=3,
            strides=1,
            padding="same",
            use_bias=False,
            data_format="channels_last",
        )
        self.bn2 = BatchNormalization()

        if residual_path:
            self.conv_shortcut = Conv2D(
                out_ch,
                kernel_size=1,
                strides=stride,
                padding="same",
                use_bias=False,
            )
            self.bn_shortcut = BatchNormalization()

        self.relu2 = LeakyReLU()

    def call(self, x, training=True):
        xs = self.relu1(self.bn1(self.conv1(x), training=training))
        xs = self.bn2(self.conv2(xs), training=training)

        if self.residual_path:
            x = self.bn_shortcut(self.conv_shortcut(x), training=training)

        xs = x + xs
        return self.relu2(xs)

class Unet(tf.keras.Model):
    def __init__(self, patch_size):
        super(Unet, self).__init__()  # Correctly initialize the base class
        self.patch_size = patch_size

        # Initialize layers
        self.conv_init = LinearTransform(patch_size=self.patch_size)
        self.resinit = ResBlock(16, residual_path=True)
        self.up_sample = UpSampling2D(size=(2, 2), interpolation='bilinear')
        self.resup = ResBlock(32, residual_path=True)

        self.pool1 = MaxPool2D(pool_size=(2, 2))

        self.resblock_down1 = ResBlock(64, residual_path=True)
        self.resblock_down11 = ResBlock(64, residual_path=False)
        self.pool2 = MaxPool2D(pool_size=(2, 2))

        self.resblock_down2 = ResBlock(128, residual_path=True)
        self.resblock_down21 = ResBlock(128, residual_path=False)
        self.pool3 = MaxPool2D(pool_size=(2, 2))

        self.resblock_down3 = ResBlock(256, residual_path=True)
        self.resblock_down31 = ResBlock(256, residual_path=False)
        self.pool4 = MaxPool2D(pool_size=(2, 2))

        self.resblock = ResBlock(512, residual_path=True)

        self.unpool3 = UpSampling2D(size=(2, 2), interpolation='bilinear')
        self.resblock_up3 = ResBlock(256, residual_path=True)
        self.resblock_up31 = ResBlock(256, residual_path=False)

        self.unpool2 = UpSampling2D(size=(2, 2), interpolation='bilinear')
        self.resblock_up2 = ResBlock(128, residual_path=True)
        self.resblock_up21 = ResBlock(128, residual_path=False)

        self.unpool1 = UpSampling2D(size=(2, 2), interpolation='bilinear')
        self.resblock_up1 = ResBlock(64, residual_path=True)

        self.unpool_final = UpSampling2D(size=(2, 2), interpolation='bilinear')
        self.resblock2 = ResBlock(32, residual_path=True)

        self.pool_final = MaxPool2D(pool_size=(2, 2))
        self.resfinal = ResBlock(32)

        self.conv_final = Conv2D(1, kernel_size=1, activation='sigmoid')

    def call(self, x, training=True):
        x_linear = self.conv_init(x, training=training)
        x = self.resinit(x_linear, training=training)
        x = self.up_sample(x)
        x = self.resup(x, training=training)

        stage1 = self.pool1(x)
        stage1 = self.resblock_down1(stage1, training=training)
        stage1 = self.resblock_down11(stage1, training=training)

        stage2 = self.pool2(stage1)
        stage2 = self.resblock_down2(stage2, training=training)
        stage2 = self.resblock_down21(stage2, training=training)

        stage3 = self.pool3(stage2)
        stage3 = self.resblock_down3(stage3, training=training)
        stage3 = self.resblock_down31(stage3, training=training)

        stage4 = self.pool4(stage3)
        stage4 = self.resblock(stage4, training=training)

        stage3 = Concatenate(axis=3)([stage3, self.unpool3(stage4)])
        stage3 = self.resblock_up3(stage3, training=training)
        stage3 = self.resblock_up31(stage3, training=training)

        stage2 = Concatenate(axis=3)([stage2, self.unpool2(stage3)])
        stage2 = self.resblock_up2(stage2, training=training)
        stage2 = self.resblock_up21(stage2, training=training)

        stage1 = Concatenate(axis=3)([stage1, self.unpool1(stage2)])
        stage1 = self.resblock_up1(stage1, training=training)

        x = Concatenate(axis=3)([x, self.unpool_final(stage1)])
        x = self.resblock2(x, training=training)

        x = self.pool_final(x)
        x = self.resfinal(x, training=training)

        seg_result = self.conv_final(x)

        return x_linear, seg_result

"""## [Part-IV] Training Model


"""

EPOCHS=200
VAL_TIME=2
LR=0.0003
BATCH_SIZE=64

checkpoint_path=dataset_path+"ckpt/"
log_path=dataset_path+"logs/"

if not os.path.exists(checkpoint_path):
  os.mkdir(checkpoint_path)

if not os.path.exists(log_path):
  os.mkdir(log_path)

"""### Training/Valid DataLoader"""

def load_image_groundtruth(img_path,groundtruth_path):
  img=tf.io.read_file(img_path)
  img=tf.image.decode_jpeg(img,channels=3)
  img=tf.image.resize(img,[patch_size,patch_size])

  groundtruth=tf.io.read_file(groundtruth_path)
  groundtruth=tf.image.decode_jpeg(groundtruth,channels=1)

  # data argument
  if random.uniform(0,1)>=0.5:
    img=tf.image.flip_left_right(img)
    groundtruth=tf.image.flip_left_right(groundtruth)

#   if random.uniform(0,1)>=0.5:
#     seeds=random.uniform(0,1)
#     img=tf.image.central_crop(img,seeds)
#     groundtruth=tf.image.central_crop(groundtruth,seeds)

  img=tf.image.resize(img,[patch_size,patch_size])
  groundtruth=tf.image.resize(groundtruth,[patch_size,patch_size])

  img/=255.0
  groundtruth=(groundtruth+40)/255.0
  groundtruth=tf.cast(groundtruth,dtype=tf.uint8)

  return img,groundtruth


train_patch_img_path_list=sorted(glob(train_patch_dir+"*-*-img.jpg"))
train_patch_groundtruth_path_list=sorted(glob(train_patch_dir+"*-*-groundtruth.jpg"))
train_patch_img_path_list,train_patch_groundtruth_path_list=shuffle(train_patch_img_path_list,train_patch_groundtruth_path_list,random_state=0)

# make sure that img-list and mask-list is in order
print(len(train_patch_img_path_list),len(train_patch_groundtruth_path_list))
print(train_patch_img_path_list[:2])
print(train_patch_groundtruth_path_list[:2])

val_patch_img_path_list=sorted(glob(train_patch_dir+"*_*_val_img.jpg"))
val_patch_groundtruth_path_list=sorted(glob(train_patch_dir+"*_*_val_groundtruth.jpg"))

print(val_patch_img_path_list[:2])
print(val_patch_groundtruth_path_list[:2])

# Training Dataloader
train_dataset=tf.data.Dataset.from_tensor_slices((train_patch_img_path_list,train_patch_groundtruth_path_list))
train_dataset=train_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_dataset = train_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)

# VAL Dataloader
val_dataset=tf.data.Dataset.from_tensor_slices((val_patch_img_path_list,val_patch_groundtruth_path_list))
val_dataset=val_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)
val_dataset =val_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)

"""### Load and Compile the Model"""

model=Unet()

# Learning rate and optimizer
cosine_decay = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=LR, first_decay_steps=12000,t_mul=1000,m_mul=0.5,alpha=1e-5)
optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay)

# loss function
loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)

# metric record
train_loss = tf.keras.metrics.Mean(name='train_loss')
train_acc=tf.keras.metrics.Mean(name='train_acc')
current_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')

val_loss = tf.keras.metrics.Mean(name='val_loss')
val_acc=tf.keras.metrics.Mean(name='val_acc')
val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')

# checkpoint
ckpt = tf.train.Checkpoint(model=model)
#ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)
#ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))

# tensorboard writer
log_dir=log_path+ datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
log_writer = tf.summary.create_file_writer(log_dir)

"""### Dice Loss & Dice Score"""

def dice(y_true,y_pred,smooth=1.):
  y_true=tf.cast(y_true,dtype=tf.float32)
  y_true_f = K.flatten(y_true)
  y_pred_f = K.flatten(y_pred)
  intersection = K.sum(y_true_f * y_pred_f)
  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def dice_loss(y_true,y_pred):
  return (1-dice(y_true,y_pred))

"""### Traing Step & Valid Step

training function and validation function
"""

def train_step(step,patch,groundtruth):
  with tf.GradientTape() as tape:

    linear,pred_seg=model(patch,training=True)
    losses = dice_loss(groundtruth, pred_seg)

  # calculate the gradient
  grads = tape.gradient(losses, model.trainable_variables)
  # bp
  optimizer.apply_gradients(zip(grads, model.trainable_variables))

  # record the training loss and accuracy
  train_loss.update_state(losses)
  train_acc.update_state(dice(groundtruth, pred_seg))



def val_step(step,patch,groundtruth):

  linear,pred_seg=model(patch,training=False)
  losses = dice_loss(groundtruth, pred_seg)

  # record the val loss and accuracy
  val_loss.update_state(losses)
  val_acc.update_state(dice(groundtruth, pred_seg))

  tf.summary.image("image",patch,step=step)
  tf.summary.image("image transform",linear,step=step)
  tf.summary.image("groundtruth",groundtruth*255,step=step)
  tf.summary.image("pred",pred_seg,step=step)
  log_writer.flush()

"""### Visualization Module

- **visualize the acc/loss
"""

# visualize the tensorflow2 model
input_arr = tf.random.uniform((1,patch_size,patch_size,1))
outputs = model(input_arr,training=False)
model.save("unet_model")
# convert tensorflow model
!python -m tf2onnx.convert --saved-model "./unet_model/" --output model.onnx

"""### Main function of training"""

lr_step=0
last_val_loss=2e10
with log_writer.as_default():
  for epoch in range(EPOCHS):
    # renew the recorder
    train_loss.reset_states()
    train_acc.reset_states()
    val_loss.reset_states()
    val_acc.reset_states()

    # training
    for tstep, (patch,groundtruth) in enumerate(train_dataset):
      train_step(lr_step,patch,groundtruth)

      tf.summary.scalar("learning_rate", optimizer._decayed_lr(tf.float32).numpy(), step=lr_step)
      print('\repoch {}, batch {}, loss:{:.4f}, dice:{:.4f}'.format(epoch + 1, tstep, train_loss.result(), train_acc.result()),end="")
      lr_step+=1

    if (epoch + 1) % VAL_TIME == 0:
      #valid
      for vstep, (patch,groundtruth) in enumerate(val_dataset):

        val_step(lr_step,patch,groundtruth)

      print('\repoch {}, batch {}, train_loss:{:.4f}, train_dice:{:.4f}, val_loss:{:.4f}, val_dice:{:.4f}'.format(epoch + 1, vstep, train_loss.result(), train_acc.result(),val_loss.result(), val_acc.result()),end="")
      tf.summary.scalar("val_loss", val_loss.result(), step=epoch)
      tf.summary.scalar("val_acc", val_acc.result(), step=epoch)

      if val_loss.result()<last_val_loss:
        ckpt.save(checkpoint_path)
        last_val_loss=val_loss.result()
    print("")
    tf.summary.scalar("train_loss", train_loss.result(), step=epoch)
    tf.summary.scalar("train_acc", train_acc.result(), step=epoch)
    log_writer.flush()

"""## [Part-V] Test and Predict

### Prepare test images
"""

# pad images
def padding_images(image,mask,stride):
    h,w=image.shape[:2]
    new_h,new_w=h,w
    while (new_h-patch_size)%stride!=0:
        new_h+=1
    while (new_w-patch_size)%stride!=0:
        new_w+=1
    pad_image=np.zeros((new_h,new_w,3))
    pad_image[:h,:w,:]=image

    pad_mask=np.zeros((new_h,new_w))
    pad_mask[:h,:w]=mask

    return pad_image,pad_mask

# images to patches
def img2patch_list(image,stride=patch_size):
    patch_list=[]
    #image_binary=0.8*image[:,:,1:2]+0.2*image[:,:,2:3]
    for j in range(0,image.shape[1]-patch_size+1,stride):
        for i in range(0,image.shape[0]-patch_size+1,stride):
            patch=image[i:i+patch_size,j:j+patch_size,:]
            patch_list.append(patch)
    return patch_list

# patches to image
def patchlist2image(patch_list,stride,image_shape):
    result=np.zeros(image_shape[:2])
    sum_matrix=np.zeros(image_shape[:2])
    index_x,index_y=0,0
    for i in range(patch_list.shape[0]):
        patch=patch_list[i,:,:,0]
        #patch=np.where(patch>0.5,1,0)
        #print(patch)
        result[index_x:index_x+patch_size,index_y:index_y+patch_size]+=patch
        sum_matrix[index_x:index_x+patch_size,index_y:index_y+patch_size]+=1
        index_x+=stride
        if index_x+patch_size>image_shape[0]:
            index_x=0
            index_y+=stride
    return result/sum_matrix

"""### main func of test"""

testmodel=Unet()
ckpts = tf.train.Checkpoint(model=testmodel)
ckpts.restore(tf.train.latest_checkpoint(checkpoint_path)).expect_partial()

stride=5

def load_test_data(image):
  #image=tf.image.decode_jpeg(image,channels=1)
  #print(image.shape)
  image=tf.image.resize(image,[patch_size,patch_size])
  #image/=255.0
  return image

for i in range(len(test_image_path_list)):
  image_path=test_image_path_list[i]
  image_name=image_path.split("/")[-1].split("_")[0]

  # load and process test images
  image=plt.imread(image_path)
  original_shape=image.shape
  mask=plt.imread(test_mask_dir+image_name+"_test_mask.gif")
  mask=np.where(mask>0,1,0)

  # image to patches
  image,pad_mask=padding_images(image,mask,stride)
  image=preprocess(image,pad_mask)
  test_patch_list=img2patch_list(image,stride)

  # test dataloader
  test_dataset=tf.data.Dataset.from_tensor_slices(test_patch_list)
  test_dataset=test_dataset.map(load_test_data)
  test_dataset=test_dataset.batch(64)
  pred_result=[]

  # test process
  print("testing image:",int(image_name))
  for batch, patch in enumerate(test_dataset):
    _,pred=testmodel(patch,training=False)

    pred=pred.numpy()
    pred_result.append(pred)
  pred_result=np.concatenate(pred_result,axis=0)

  # patches to image
  print("post processing:",image_name)
  pred_image=patchlist2image(pred_result,stride,image.shape)

  pred_image=pred_image[:original_shape[0],:original_shape[1]]

  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))
  print(mask.shape)
  mask = cv2.erode(mask.astype(np.uint8), kernel)

  pred_image=pred_image*mask
  pred_image=np.where(pred_image>0.5,1,0)

  # visualize the test result
  plt.figure(figsize=(8,8))
  plt.title(image_name+"-("+str(image.shape[0])+","+str(image.shape[1])+")")
  plt.imshow(pred_image,cmap=plt.cm.gray)
  plt.show()

  plt.imsave(test_save_dir+str(int(image_name))+".png",pred_image,cmap = plt.cm.gray)

"""# [Part-VI] Evaluation


- sensitivity and specificity
- AUC and PR
- dice score
"""

test_groundtruth_path_list=sorted(glob(test_groundtruth_dir+"*.gif"))
test_pred_path_list=sorted(glob(test_save_dir+"*.png"))

dice_list=[]
roc_list=[]
pr_list=[]
tpr_list=[]
tnr_list=[]
sum_tp=0
sum_tn=0
sum_fp=0
sum_fn=0

roc = tf.keras.metrics.AUC(num_thresholds=200,curve="ROC")
pr = tf.keras.metrics.AUC(num_thresholds=200,curve="PR")
recall=tf.keras.metrics.Recall()


tn=tf.keras.metrics.TrueNegatives()
tp=tf.keras.metrics.TruePositives()
fn=tf.keras.metrics.FalseNegatives()
fp=tf.keras.metrics.FalsePositives()

for idx in range(len(test_groundtruth_path_list)):
    name=test_groundtruth_path_list[idx].split("/")[-1].split(".")[0].split("_")[0]
    roc.reset_states()
    pr.reset_states()
    tn.reset_states()
    fn.reset_states()
    tp.reset_states()
    fp.reset_states()

    groundtruth=plt.imread(test_groundtruth_path_list[idx])
    preds=plt.imread(test_save_dir+str(int(name))+".png")
    groundtruth=np.array(groundtruth,dtype=np.float32)
    groundtruth=groundtruth/255.0

    roc.update_state(groundtruth,preds[:,:,0])   #png image is 4-channel
    pr.update_state(groundtruth,preds[:,:,0])
    tn.update_state(groundtruth,preds[:,:,0])
    tp.update_state(groundtruth,preds[:,:,0])
    fn.update_state(groundtruth,preds[:,:,0])
    fp.update_state(groundtruth,preds[:,:,0])

    dice_list.append(dice(groundtruth,preds[:,:,0]).numpy())
    roc_list.append(roc.result().numpy())
    pr_list.append(pr.result().numpy())

    current_tn=tn.result().numpy()
    current_tp=tp.result().numpy()
    current_fn=fn.result().numpy()
    current_fp=fp.result().numpy()

    sum_tp+=current_tp
    sum_tn+=current_tn
    sum_fp+=current_fp
    sum_fn+=current_fn

    tpr_list.append(current_tp/(current_tp+current_fn))
    tnr_list.append(current_tn/(current_tn+current_fp))

print("average dice score for all predict vessel masks:",np.mean(dice_list))
print("average AUC for all predict vessel masks:",np.mean(roc_list))
print("average PR for all predict vessel masks:",np.mean(pr_list))
print("average recall(sensitivity) for all predict vessel masks:",np.mean(tpr_list))
print("average specificity for all predict vessel masks:",np.mean(tnr_list))

"""- confusion matrix"""

predict = ["Positive","Negative"]
actual = [ "Positive","Negative"]
classes = list(set(actual))
classes.sort(reverse=True)
confusion_matrix=[[sum_tp,sum_fn],[sum_fp,sum_tn]]
print("confusion",confusion_matrix)



plt.figure(figsize=(8,8))
font_size=18
plt.imshow(confusion_matrix, cmap=plt.cm.Blues)
indices = range(len(confusion_matrix))
plt.xticks(indices, classes,rotation=40,fontsize=font_size)
plt.yticks([0.00,1.00], classes,fontsize=font_size)
plt.ylim(1.5 , -0.5)

plt.title("Confusion matrix (Pixel Level)",fontdict={'weight':'normal','size': font_size})
plt.xlabel('Predict Label',fontsize=font_size)
plt.ylabel('Actual Label',fontsize=font_size)

for first_index in range(len(confusion_matrix)):
    for second_index in range(len(confusion_matrix[first_index])):
        if confusion_matrix[first_index][second_index]>2e6:
            text_color="w"
        else:
            text_color="black"
        plt.text(first_index, second_index, confusion_matrix[first_index][second_index],fontsize=font_size, color = text_color,verticalalignment='center',horizontalalignment='center',)

cb=plt.colorbar()
cb.ax.tick_params(labelsize=font_size)
plt.show()

